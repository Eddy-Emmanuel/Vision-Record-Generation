{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9151846,"sourceType":"datasetVersion","datasetId":5528323},{"sourceId":9152166,"sourceType":"datasetVersion","datasetId":5528563}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics ","metadata":{"execution":{"iopub.status.busy":"2024-08-11T17:46:25.908015Z","iopub.execute_input":"2024-08-11T17:46:25.908567Z","iopub.status.idle":"2024-08-11T17:46:40.923462Z","shell.execute_reply.started":"2024-08-11T17:46:25.908537Z","shell.execute_reply":"2024-08-11T17:46:40.922278Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.2.75-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.4)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.2)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.16.2)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.5.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.2.75-py3-none-any.whl (865 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.6/865.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.2.75 ultralytics-thop-2.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport datetime\nfrom ultralytics import YOLO\nimport webcolors\nfrom scipy.spatial import KDTree\nfrom transformers import BlipProcessor, BlipForConditionalGeneration\nimport torch\nfrom PIL import Image\n\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-11T17:46:40.925787Z","iopub.execute_input":"2024-08-11T17:46:40.926183Z","iopub.status.idle":"2024-08-11T17:46:47.123284Z","shell.execute_reply.started":"2024-08-11T17:46:40.926146Z","shell.execute_reply":"2024-08-11T17:46:47.122504Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print(webcolors.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T17:46:47.124478Z","iopub.execute_input":"2024-08-11T17:46:47.124977Z","iopub.status.idle":"2024-08-11T17:46:47.130278Z","shell.execute_reply.started":"2024-08-11T17:46:47.124942Z","shell.execute_reply":"2024-08-11T17:46:47.129432Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"1.13\n","output_type":"stream"}]},{"cell_type":"code","source":"image_path = [\"/kaggle/input/random-image-on-internet/test_image.png\",\n              \"/kaggle/input/client-test-image/test_image_1.jpg\", \n              \"/kaggle/input/client-test-image/test_image_2.jpg\",\n              \"/kaggle/input/client-test-image/test_image_3.jpg\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T14:05:45.261174Z","iopub.execute_input":"2024-08-11T14:05:45.261573Z","iopub.status.idle":"2024-08-11T14:05:45.266269Z","shell.execute_reply.started":"2024-08-11T14:05:45.261547Z","shell.execute_reply":"2024-08-11T14:05:45.265202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def LoadImage(image_path):\n    # Load image\n\n    image = Image.open(image_path).convert(\"RGB\")\n    \n    # image to array\n\n    image_to_array = np.array(image)\n    \n    plt.imshow(image)\n    plt.axis(\"off\")\n    plt.show()\n\n    return image_to_array","metadata":{"execution":{"iopub.status.busy":"2024-08-11T14:05:55.979512Z","iopub.execute_input":"2024-08-11T14:05:55.979914Z","iopub.status.idle":"2024-08-11T14:05:55.985914Z","shell.execute_reply.started":"2024-08-11T14:05:55.979881Z","shell.execute_reply":"2024-08-11T14:05:55.984800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the BLIP model and processor for image captioning\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\nmodel = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\").to(\"cuda\")\n\n# Precompute the RGB values and corresponding color names\ncss3_db = {name: webcolors.hex_to_rgb(hex_) for hex_, name in webcolors.CSS3_HEX_TO_NAMES.items()}\nnames = list(css3_db.keys())\nrgb_values = np.array([css3_db[name] for name in names])\n\n# Build a KDTree for fast nearest neighbor search\nkd_tree = KDTree(rgb_values)\n\ndef get_color_name(rgb_color):\n    dist, idx = kd_tree.query(rgb_color)\n    return names[idx]\n\ndef get_primary_color(image, bbox):\n    x, y, w, h = bbox\n    roi = image[y:y+h, x:x+w]\n    roi = cv2.resize(roi, (10, 10), interpolation=cv2.INTER_AREA)\n    avg_color = roi.mean(axis=0).mean(axis=0)\n    avg_color = avg_color.astype(int)\n    avg_color_rgb = avg_color[::-1].tolist()\n    color_name = get_color_name(avg_color_rgb)\n    return color_name\n\ndef generate_caption(image):\n    if image.mode != \"RGB\":\n        image = image.convert(mode=\"RGB\")\n    \n    # Unconditional image captioning\n    inputs = processor(image, return_tensors=\"pt\").to(\"cuda\")\n    out = model.generate(**inputs)\n    caption = processor.decode(out[0], skip_special_tokens=True).strip()\n    \n    return caption\n\ndef generate_vision_record(image: np.array) -> dict:\n    yolo_model = YOLO('yolov10n.pt')\n    \n    results = yolo_model(image)\n\n    detected_objects = []\n    activities = []\n    object_colors = []\n    bounding_boxes = []\n\n    for result in results:\n        for bbox, class_id, confidence in zip(result.boxes.xyxy, result.boxes.cls, result.boxes.conf):\n            bbox = bbox.int().tolist()\n            class_name = yolo_model.names[int(class_id)]\n            detected_objects.append(class_name)\n\n            # Extract the bounding box region and convert to PIL image for image captioning\n            cropped_img = image[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n            cropped_img = Image.fromarray(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))\n\n            # Generate a caption for the cropped image (if needed)\n            caption = generate_caption(cropped_img)\n            activities.append(caption)  # Using 'activities' to store captions\n\n            color = get_primary_color(image, bbox)\n            object_colors.append(color)\n            \n            bounding_boxes.append(bbox)\n\n    frame_size = image.shape[:2]\n\n    # Convert the entire frame to PIL image for full-frame captioning\n    full_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n\n    # Generate a caption for the entire frame\n    frame_summary = generate_caption(full_image)\n\n    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n\n    vision_record = {\n        \"Time\": timestamp,\n        \"Objects\": detected_objects,\n        \"Objects Activities\": activities,  \n        \"Object Colors\": object_colors,\n        \"Object Bounding Boxes\": bounding_boxes,\n        \"Frame Size\": frame_size,\n        \"Frame Summary\": frame_summary \n    }\n\n    return vision_record","metadata":{"execution":{"iopub.status.busy":"2024-08-11T14:26:20.791047Z","iopub.execute_input":"2024-08-11T14:26:20.791867Z","iopub.status.idle":"2024-08-11T14:26:23.365077Z","shell.execute_reply.started":"2024-08-11T14:26:20.791831Z","shell.execute_reply":"2024-08-11T14:26:23.364221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_1 = LoadImage(image_path=image_path[0])","metadata":{"execution":{"iopub.status.busy":"2024-08-11T14:26:23.366957Z","iopub.execute_input":"2024-08-11T14:26:23.367270Z","iopub.status.idle":"2024-08-11T14:26:23.600937Z","shell.execute_reply.started":"2024-08-11T14:26:23.367244Z","shell.execute_reply":"2024-08-11T14:26:23.600012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate the vision record\nvision_record = generate_vision_record(image_1)\n\nvision_record","metadata":{"execution":{"iopub.status.busy":"2024-08-11T14:26:23.602073Z","iopub.execute_input":"2024-08-11T14:26:23.602345Z","iopub.status.idle":"2024-08-11T14:26:32.958844Z","shell.execute_reply.started":"2024-08-11T14:26:23.602321Z","shell.execute_reply":"2024-08-11T14:26:32.957978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_2 = LoadImage(image_path=image_path[1])","metadata":{"execution":{"iopub.status.busy":"2024-08-11T14:07:12.334189Z","iopub.execute_input":"2024-08-11T14:07:12.334870Z","iopub.status.idle":"2024-08-11T14:07:12.584852Z","shell.execute_reply.started":"2024-08-11T14:07:12.334841Z","shell.execute_reply":"2024-08-11T14:07:12.583967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate the vision record\nvision_record = generate_vision_record(image_2)\n\nvision_record","metadata":{"execution":{"iopub.status.busy":"2024-08-11T14:07:12.786939Z","iopub.execute_input":"2024-08-11T14:07:12.787907Z","iopub.status.idle":"2024-08-11T14:07:14.671914Z","shell.execute_reply.started":"2024-08-11T14:07:12.787875Z","shell.execute_reply":"2024-08-11T14:07:14.670767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_3 = LoadImage(image_path=image_path[2])","metadata":{"execution":{"iopub.status.busy":"2024-08-11T14:08:11.499171Z","iopub.execute_input":"2024-08-11T14:08:11.499945Z","iopub.status.idle":"2024-08-11T14:08:11.764020Z","shell.execute_reply.started":"2024-08-11T14:08:11.499913Z","shell.execute_reply":"2024-08-11T14:08:11.762862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate the vision record\nvision_record = generate_vision_record(image_3)\n\nvision_record","metadata":{"execution":{"iopub.status.busy":"2024-08-11T14:08:34.757663Z","iopub.execute_input":"2024-08-11T14:08:34.758064Z","iopub.status.idle":"2024-08-11T14:08:38.955034Z","shell.execute_reply.started":"2024-08-11T14:08:34.758034Z","shell.execute_reply":"2024-08-11T14:08:38.954059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_4 = LoadImage(image_path=image_path[3])","metadata":{"execution":{"iopub.status.busy":"2024-08-11T14:08:58.773035Z","iopub.execute_input":"2024-08-11T14:08:58.773890Z","iopub.status.idle":"2024-08-11T14:08:59.106805Z","shell.execute_reply.started":"2024-08-11T14:08:58.773859Z","shell.execute_reply":"2024-08-11T14:08:59.105909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate the vision record\nvision_record = generate_vision_record(image_4)\n\nvision_record","metadata":{"execution":{"iopub.status.busy":"2024-08-11T14:09:15.259144Z","iopub.execute_input":"2024-08-11T14:09:15.259812Z","iopub.status.idle":"2024-08-11T14:09:20.122117Z","shell.execute_reply.started":"2024-08-11T14:09:15.259779Z","shell.execute_reply":"2024-08-11T14:09:20.121065Z"},"trusted":true},"execution_count":null,"outputs":[]}]}